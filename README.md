# Low-Resource-Hallucination-Detection-in-LLMs-on-Multi-Task-Datasets
The work proposes an iterative self-training transformer model based approach, combining a small manually labeled set with a confidence-based scoring technique to pseudo label other unlabeled instances, allowing the model to improve performance while requiring minimal labeled data. 
